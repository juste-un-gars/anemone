# ü™∏ Anemone - √âtat du Projet

**Derni√®re session** : 2025-11-16 (Session 18 - Interface admin de restauration utilisateurs + Fix bulk restore)
**Prochaine session** : Tests interface utilisateur + Audit s√©curit√©
**Status** : üü¢ COMPL√àTE - Restauration admin fonctionnelle √† 100%

> **Note** : L'historique des sessions 1-7 a √©t√© archiv√© dans `SESSION_STATE_ARCHIVE.md`
> **Note** : Les d√©tails techniques des sessions 8-11 sont dans `SESSION_STATE_ARCHIVE_SESSIONS_8_11.md`
> **Note** : Les d√©tails techniques des sessions 12-16 sont dans `SESSION_STATE_ARCHIVE_SESSIONS_12_16.md`

---

## üéØ √âtat actuel

### ‚úÖ Fonctionnalit√©s compl√®tes et test√©es

1. **Configuration initiale (Setup)**
   - Choix langue (FR/EN)
   - Cr√©ation premier admin
   - G√©n√©ration cl√© de chiffrement

2. **Authentification & S√©curit√©**
   - Login/logout multi-utilisateurs
   - Sessions s√©curis√©es
   - HTTPS avec certificat auto-sign√©
   - R√©initialisation mot de passe par admin

3. **Gestion utilisateurs**
   - Cr√©ation utilisateurs par admin
   - Activation par lien temporaire (24h)
   - Cr√©ation automatique user syst√®me + SMB
   - **Suppression compl√®te** : Efface DB, fichiers disque, user SMB, user syst√®me
   - **Confirmation renforc√©e** : Double confirmation + saisie nom utilisateur
   - **Cl√© de chiffrement unique par utilisateur** : 32 bytes, g√©n√©r√©e √† l'activation

4. **Partages SMB automatiques**
   - 2 partages par user : `backup_username` + `data_username`
   - Cr√©ation auto lors activation
   - Permissions et ownership automatiques
   - Configuration SELinux automatique
   - **Privacy** : Chaque user ne voit que ses partages
   - **Corbeille int√©gr√©e** : VFS recycle module Samba

5. **Corbeille (Trash/Recycle Bin)**
   - Interception suppressions SMB via Samba VFS
   - D√©placement fichiers dans `.trash/%U/`
   - Interface web de gestion
   - Restauration fichiers
   - Suppression d√©finitive
   - Vidage corbeille complet

6. **Gestion pairs P2P**
   - CRUD complet avec √©dition
   - Test connexion HTTPS avec authentification
   - Statuts (online/offline/error)
   - **Synchronisation manuelle** : Bouton sync par partage
   - **Synchronisation automatique** : Scheduler int√©gr√© avec fr√©quences personnalisables
   - **Chiffrement E2E** : AES-256-GCM par utilisateur
   - **Authentification P2P** : Protection endpoints par mot de passe

7. **Syst√®me de Quotas**
   - **Quotas Btrfs kernel** : Enforcement automatique au niveau filesystem
   - Subvolumes Btrfs par partage
   - Interface admin : D√©finition quotas backup + data
   - Dashboard user : Barres progression avec alertes (vert/jaune/orange/rouge)
   - Migration automatique : `anemone-migrate` pour convertir dirs existants
   - **Fallback mode** : ext4/XFS/ZFS fonctionnent sans enforcement

8. **Chiffrement End-to-End**
   - Cl√© unique 32 bytes par utilisateur
   - Chiffrement AES-256-GCM avec AEAD
   - Hi√©rarchie : Master key ‚Üí User keys (chiffr√©es)
   - Backups P2P chiffr√©s automatiquement
   - Protection m√™me si peer compromis

9. **Synchronisation incr√©mentale**
   - Syst√®me de manifest pour tracking fichiers
   - Upload fichier par fichier (type rclone)
   - Seulement les fichiers modifi√©s sont transf√©r√©s
   - Suppression automatique fichiers obsol√®tes
   - Chaque fichier chiffr√© individuellement
   - Stockage : `/srv/anemone/backups/incoming/{user_id}_{share_name}/`

10. **Scheduler automatique**
    - Goroutine background v√©rifiant toutes les 1 minute
    - Configuration par pair (interval/daily/weekly/monthly)
    - Bouton "Forcer la synchronisation" pour trigger manuel
    - Logs d√©taill√©s dans la console serveur
    - Dashboard utilisateur affiche "Derni√®re sauvegarde"

11. **Authentification P2P par mot de passe**
    - **Mot de passe serveur** : Prot√®ge les endpoints `/api/sync/*` contre acc√®s non autoris√©s
    - **Mot de passe pair** : Authentification aupr√®s des serveurs distants
    - Middleware `syncAuthMiddleware` avec header `X-Sync-Password`
    - Interface admin `/admin/settings` pour configurer le mot de passe serveur
    - Champ mot de passe lors de l'ajout/√©dition de pairs
    - Hachage bcrypt c√¥t√© serveur (stockage s√©curis√©)
    - R√©trocompatibilit√© : Sans mot de passe configur√© = acc√®s libre

12. **Gestion des backups entrants**
    - Vue `/admin/incoming` pour visualiser les pairs qui stockent des backups
    - Statistiques : nombre de pairs, fichiers, espace utilis√©
    - Suppression de backups entrants
    - Carte dashboard pour acc√®s rapide

13. **√âdition de pairs**
    - Interface `/admin/peers/{id}/edit` pour modifier la configuration
    - Modification nom, adresse, port, mot de passe, statut, fr√©quence sync
    - Gestion intelligente du mot de passe (conserver/modifier/supprimer)
    - Test d'authentification int√©gr√© au bouton "Test"
    - D√©tection automatique des erreurs d'authentification (401/403)

14. **Installation automatis√©e**
    - Script `install.sh` z√©ro-touch
    - Configuration compl√®te syst√®me
    - Support multi-distro (Fedora/RHEL/Debian)

15. **Restauration de fichiers avec interface web** (Session 12)
    - Liste des backups disponibles sur tous les pairs distants
    - Navigation dans l'arborescence des fichiers chiffr√©s
    - D√©chiffrement automatique c√¥t√© serveur d'origine
    - **S√©lection multiple** : Checkboxes pour fichiers et dossiers
    - **T√©l√©chargement ZIP** : Plusieurs fichiers/dossiers en un clic
    - **Expansion r√©cursive** : S√©lection d'un dossier inclut tous les sous-fichiers
    - Support des chemins avec espaces et caract√®res sp√©ciaux

16. **Backups serveur automatiques** (Session 15)
    - Scheduler quotidien √† 4h du matin
    - Rotation automatique (10 derniers backups)
    - Re-chiffrement √† la vol√©e pour t√©l√©chargement s√©curis√©
    - Interface admin `/admin/backup`

17. **Restauration compl√®te du serveur** (Sessions 16-17)
    - Script `restore_server.sh` pour restauration compl√®te
    - **Re-chiffrement automatique** des mots de passe SMB avec nouvelle master key
    - **Re-chiffrement automatique** des cl√©s utilisateur avec nouvelle master key
    - Cr√©ation automatique des utilisateurs syst√®me et SMB
    - Configuration automatique des partages
    - Flag `server_restored` pour afficher page d'avertissement

### üöÄ D√©ploiement

**DEV (localhost)** : ‚úÖ D√©veloppement actif
**FR1 (192.168.83.16)** : ‚úÖ Serveur source avec utilisateurs et fichiers
**FR2 (192.168.83.37)** : ‚úÖ Serveur de backup (stockage pairs)
**FR3 (192.168.83.38)** : ‚úÖ Serveur restaur√© (tests disaster recovery)

**Tests valid√©s** :
- ‚úÖ Acc√®s SMB depuis Windows : OK
- ‚úÖ Acc√®s SMB depuis Android : OK
- ‚úÖ Cr√©ation/lecture/√©criture fichiers : OK
- ‚úÖ **Blocage quota d√©pass√©** : OK
- ‚úÖ Privacy SMB (chaque user voit uniquement ses partages) : OK
- ‚úÖ Multi-utilisateurs : OK
- ‚úÖ SELinux (Fedora) : OK
- ‚úÖ **Synchronisation automatique** : OK
- ‚úÖ **Synchronisation incr√©mentale** : OK (fichiers modifi√©s/supprim√©s d√©tect√©s)
- ‚úÖ **Dashboard "Derni√®re sauvegarde"** : OK
- ‚úÖ **Authentification P2P** : OK (401/403/200 selon mot de passe)
- ‚úÖ **Restauration fichiers depuis pairs** : OK (Session 12)
- ‚úÖ **T√©l√©chargement ZIP multiple** : OK (Session 12)
- ‚úÖ **Backups serveur quotidiens** : OK (Session 15)
- ‚úÖ **Restauration config serveur** : OK (Session 16-17)
- ‚úÖ **Restauration mots de passe SMB** : OK (Session 16)
- ‚úÖ **Re-chiffrement cl√©s utilisateur** : OK (Session 17)

**Structure de production** :
- Code : `~/anemone/` (repo git, binaires)
- Donn√©es : `/srv/anemone/` (db, certs, shares, smb, backups)
- Base de donn√©es : `/srv/anemone/db/anemone.db`
- Binaires syst√®me : `/usr/local/bin/` (anemone, anemone-dfree, anemone-smbgen, anemone-migrate)
- Service : `systemd` (d√©marrage automatique)

### üì¶ Liens utiles

- **GitHub** : https://github.com/juste-un-gars/anemone
- **Donation PayPal** : https://paypal.me/justeungars83

---

## üìã Sessions archiv√©es

- **Sessions 1-7** : Voir `SESSION_STATE_ARCHIVE.md`
- **Sessions 8-11** : Voir `SESSION_STATE_ARCHIVE_SESSIONS_8_11.md`
- **Sessions 12-16** : Voir `SESSION_STATE_ARCHIVE_SESSIONS_12_16.md`

---

## üîß Session 13 - 10 Novembre 2025 - Fr√©quence de synchronisation par pair (avec Interval)

### üéØ Objectif

Permettre de configurer une fr√©quence de synchronisation ind√©pendante pour chaque pair, incluant une option "Interval" pour synchroniser toutes les X minutes ou heures.

### ‚úÖ Architecture impl√©ment√©e

**Avant** : Configuration globale dans `sync_config` ‚Üí tous les pairs synchronis√©s en m√™me temps
**Apr√®s** : Configuration individuelle par pair ‚Üí chaque pair a sa propre fr√©quence et son propre timestamp de derni√®re sync

**Fr√©quences support√©es** :
- **Interval** : Synchronisation √† intervalle r√©gulier (ex: toutes les 30 minutes, toutes les 2 heures)
- **Daily** : Synchronisation quotidienne √† une heure fixe (ex: 23:00)
- **Weekly** : Synchronisation hebdomadaire un jour sp√©cifique (ex: Samedi 23:00)
- **Monthly** : Synchronisation mensuelle un jour sp√©cifique (ex: 1er du mois √† 23:00)

**Statut** : üü¢ COMPL√àTE ET TEST√âE

---

## üîß Session 17 - 15 Novembre 2025 - Re-chiffrement des cl√©s utilisateur lors de la restauration

**Date** : 2025-11-15
**Objectif** : Corriger le probl√®me critique de restauration des fichiers apr√®s restauration serveur
**Priorit√©** : üî¥ CRITIQUE ‚Üí üü¢ R√âSOLUE

### üêõ Probl√®me d√©couvert

Lors des tests de restauration FR1 ‚Üí FR3 avec backup sur FR2, la restauration automatique √©chouait avec :
```
Bulk restore failed: failed to decrypt user key:
failed to decrypt: cipher: message authentication failed
```

### üîç Analyse du probl√®me

**Architecture du chiffrement** :
```
Master Key (unique par serveur)
    ‚Üì chiffre
User Encryption Key (unique par utilisateur)
    ‚Üì chiffre
Fichiers utilisateur (backup sur pairs distants)
```

**Probl√®me** :
- FR1 g√©n√®re une master key unique : `MK_FR1`
- `encryption_key_encrypted` est chiffr√© avec `MK_FR1`
- FR3 g√©n√®re une NOUVELLE master key : `MK_FR3`
- Le script `restore_server.sh` restaure `encryption_key_encrypted` tel quel (chiffr√© avec `MK_FR1`)
- Quand FR3 essaie de restaurer les fichiers, impossible de d√©chiffrer la cl√© utilisateur

### ‚úÖ Solution impl√©ment√©e

**Principe** : Re-chiffrer `encryption_key_encrypted` avec la nouvelle master key lors de la restauration.

**Outil cr√©√©** : `cmd/anemone-reencrypt-key/main.go`
- D√©chiffre la cl√© utilisateur avec l'ancienne master key
- Re-chiffre avec la nouvelle master key
- Retourne la cl√© re-chiffr√©e en base64

**Script modifi√©** : `restore_server.sh`
- Extrait l'ancienne master key du backup
- G√©n√®re une nouvelle master key pour le serveur restaur√©
- Re-chiffre `password_encrypted` ET `encryption_key_encrypted` pour chaque utilisateur
- Ins√®re les valeurs re-chiffr√©es dans la base de donn√©es

### üî® Probl√®mes rencontr√©s et correctifs appliqu√©s

#### Probl√®mes r√©solus (commits)
1. ‚úÖ **Double encodage base64** (commit 4fb306d)
2. ‚úÖ **Type de donn√©es dans export** (commit fbcf7b9)
3. ‚úÖ **Lecture SQLite BLOB vs TEXT** (commit c09574d)
4. ‚úÖ **Insertion TEXT au lieu de BLOB** (commit 2c93955)
5. ‚úÖ **Format Manifest incompatible** (commit 7c48184)
6. ‚úÖ **Share path hardcod√©** (commit daaa39d)
7. ‚úÖ **Convention de nommage shares** (commit 0335cdb)

### üìù Commits

```
4fb306d - fix: Remove double base64 encoding in restore script
fbcf7b9 - fix: Change EncryptionKeyEncrypted type to string
c09574d - fix: Use sql.NullString to read encryption_key_encrypted as TEXT
2c93955 - fix: Insert encryption_key_encrypted as TEXT, not BLOB (Session 17)
7c48184 - fix: Fix manifest Files type mismatch (Session 17)
daaa39d - fix: Use database share path instead of hardcoded names (Session 17)
0335cdb - fix: Apply backup_{username} convention in list-user-backups API
```

**Statut** : üü¢ **COMPL√àTE - Tous les probl√®mes d'encodage et de manifest r√©solus**

---

## üîß Session 18 - 15 Novembre 2025 - Interface admin de restauration utilisateurs

**Date** : 2025-11-15
**Objectif** : Cr√©er une interface admin s√©curis√©e pour restaurer les fichiers de tous les utilisateurs apr√®s disaster recovery
**Priorit√©** : üî¥ CRITIQUE

### üéØ Contexte

Suite √† la Session 17, un probl√®me majeur a √©t√© identifi√© :
- **Probl√®me** : Lors de la restauration serveur, le scheduler d√©marre automatiquement
- **Cons√©quence** : Le serveur restaur√© (FR3) d√©tecte "tous les fichiers supprim√©s" car les shares sont vides
- **Catastrophe** : FR3 envoie des commandes DELETE √† FR2, qui supprime tous les backups !
- **Boucle** : FR1 upload ‚Üí FR3 DELETE ‚Üí FR1 re-upload ‚Üí FR3 DELETE...

### ‚úÖ Solution impl√©ment√©e

**Architecture s√©curis√©e** :
1. **D√©sactivation automatique des pairs** : `restore_server.sh` ex√©cute `UPDATE peers SET sync_enabled = 0`
2. **Interface admin d√©di√©e** : `/admin/restore-users` pour restauration contr√¥l√©e
3. **Suppression restauration utilisateur** : Les utilisateurs non-admin ne peuvent plus d√©clencher de restauration automatique
4. **Workflow s√©curis√©** :
   ```
   Restauration serveur ‚Üí Peers d√©sactiv√©s ‚Üí Admin restaure les fichiers ‚Üí Admin r√©active les pairs
   ```

### üî® Composants cr√©√©s/modifi√©s

**1. Nouveaux handlers** (`internal/web/router.go`)

**`handleAdminRestoreUsers()`** :
- R√©cup√®re tous les utilisateurs (sauf admin)
- Interroge tous les pairs (m√™me d√©sactiv√©s) pour lister les backups disponibles
- Appelle `/api/sync/list-user-backups` sur chaque pair
- Construit une liste de `UserBackup` avec : UserID, Username, PeerID, PeerName, ShareName, FileCount, TotalSize, LastModified
- Rend le template `admin_restore_users.html`

**`handleAdminRestoreUsersRestore()`** :
- Re√ßoit `user_id`, `peer_id`, `share_name` depuis le formulaire
- Lance `bulkrestore.BulkRestoreFromPeer()` en arri√®re-plan (goroutine)
- Retourne une r√©ponse JSON imm√©diate pour √©viter timeout
- Format : `{"success": true, "message": "Restauration lanc√©e"}`

**2. Template admin** (`web/templates/admin_restore_users.html` - NOUVEAU)

Interface Tailwind CSS avec :
- **En-t√™te** : Navigation avec logo, r√¥le admin, logout
- **Tableau des backups** :
  - Colonnes : Utilisateur, Serveur pair, Partage, Fichiers, Taille, Derni√®re modification, Actions
  - Ligne par backup disponible
  - Bouton "Restaurer" par ligne (appelle `restoreUser()` JavaScript)
- **Bouton "Restaurer tous les utilisateurs"** : Lance `restoreAll()` JavaScript
- **Message de statut** : Div cach√©e pour afficher succ√®s/erreurs
- **JavaScript** :
  - `restoreUser(userID, peerID, shareName, username)` : POST `/admin/restore-users/restore` pour un utilisateur
  - `restoreAll()` : Boucle sur tous les backups et lance chaque restauration
  - Mise √† jour du statut en temps r√©el

**3. Template restore_warning modifi√©** (`web/templates/restore_warning.html`)

**Pour les utilisateurs non-admin** :
- ‚ùå **SUPPRIM√â** : Option "Restauration automatique" avec dropdown de s√©lection peer
- ‚úÖ **CONSERV√â** : Option "Restauration manuelle" (transf√©rer fichiers via SMB)
- Message : "Je vais transf√©rer mes fichiers depuis mon PC via SMB"

**Pour les administrateurs** :
- ‚úÖ Option 1 : Restauration manuelle (identique aux users)
- ‚úÖ Option 2 : **Lien vers interface admin** (`/admin/restore-users`)
  - Description : "Acc√©der √† l'interface admin pour restaurer automatiquement les fichiers de tous les utilisateurs depuis les serveurs pairs"
  - Bouton : "üîß Acc√©der √† l'interface de restauration admin"

**4. Script de restauration modifi√©** (`restore_server.sh`)

Ajout de la d√©sactivation automatique des pairs :
```bash
# Disable all peers to prevent automatic sync from deleting backup files
# Admin must manually re-enable peers after restoring user files
sqlite3 "$DB_FILE" "UPDATE peers SET sync_enabled = 0;"
echo -e "${YELLOW}‚ö†Ô∏è  All peers have been disabled to prevent data loss${NC}"
echo -e "${YELLOW}   Re-enable peers after restoring user files from admin interface${NC}"
```

**Position** : Apr√®s insertion des pairs, avant le message de fin de restauration

### üêõ Probl√®mes rencontr√©s et correctifs

#### 1. Peers filtr√©s par `sync_enabled`
**Probl√®me** : Page admin affichait "Aucune sauvegarde disponible"
**Cause** : Code dans `handleAdminRestoreUsers` filtrait les pairs d√©sactiv√©s :
```go
if !peer.SyncEnabled {
    continue  // Skippait tous les pairs d√©sactiv√©s par restore_server.sh !
}
```
**Fix** : Suppression du filtre, avec commentaire explicatif
```go
// Query each peer for this user's backups
// Note: We query ALL peers, even disabled ones, because we want to list
// available backups for restoration (peers are disabled after server restore)
for _, peer := range allPeers {
```

#### 2. Template FormatTime manquant param√®tre `lang`
**Probl√®me** : Colonne "Derni√®re modification" affichait "Internal server error"
**Cause** : Template appelait `{{FormatTime .LastModified}}` mais la fonction attend 2 param√®tres : `func(t time.Time, lang string)`
**Fix** : Correction template
```html
<!-- Avant -->
{{FormatTime .LastModified}}

<!-- Apr√®s -->
{{FormatTime .LastModified $.Lang}}
```

#### 3. Template non d√©ploy√© sur FR3
**Probl√®me** : Erreur persistait apr√®s recompilation binaire
**Cause** : Les templates sont charg√©s depuis le disque (`/srv/anemone/web/templates/`) et non embarqu√©s dans le binaire
**Fix** : Copie manuelle du template modifi√© :
```bash
scp web/templates/admin_restore_users.html franck@192.168.83.38:/tmp/
ssh franck@192.168.83.38 "sudo mv /tmp/admin_restore_users.html /srv/anemone/web/templates/"
sudo systemctl restart anemone
```

### ‚úÖ Probl√®mes r√©solus

#### 1. Restauration √©chouait avec erreurs 400 (R√âSOLU)
**Sympt√¥me initial** :
- La restauration se lan√ßait mais tous les t√©l√©chargements √©chouaient avec "status 400"
- Logs : `Error: Failed to download : status 400` (sans nom de fichier)
- 7 fichiers d√©tect√©s mais 0 bytes restaur√©s, 7 erreurs

**Diagnostic** :
- Ajout de logs DEBUG dans `bulkrestore.BulkRestoreFromPeer()`
- D√©couverte : Le champ `Path` dans `FileEntry` √©tait **vide** pour tous les fichiers
- La cl√© de la map contenait le bon chemin (`'02.3mf'`), mais `file.Path` √©tait `""`
- Les requ√™tes HTTP envoyaient donc `path=` (vide) ‚Üí 400 Bad Request

**Cause racine** :
- Le manifest stocke les fichiers avec le chemin comme **cl√© de la map**
- Le champ `file.Path` √† l'int√©rieur de la structure `FileEntry` n'√©tait pas rempli
- Le code it√©rait avec `for _, file := range manifest.Files` et utilisait `file.Path`
- R√©sultat : toutes les requ√™tes avaient un param√®tre `path` vide

**Solution** :
- Modifier la boucle : `for filePath, file := range manifest.Files`
- Utiliser `filePath` (cl√© de la map) au lieu de `file.Path` (champ vide)
- Mettre √† jour toutes les r√©f√©rences pour utiliser la variable `filePath`

**R√©sultat** :
```
Bulk restore completed for user 2: 7 files, 280596 bytes, 0 errors
```
‚úÖ **100% de succ√®s !**

#### 2. Fichiers restaur√©s appartenaient √† root:root (R√âSOLU)
**Sympt√¥me** :
- Les fichiers restaur√©s appartenaient √† `root:root` au lieu de `test:test`
- Probl√®me d'acc√®s SMB potentiel

**Solution** :
- Ajout de la fonction helper `setOwnership(path, username)`
- Utilise `user.Lookup()` pour r√©cup√©rer UID/GID
- Appelle `os.Chown()` apr√®s cr√©ation de chaque fichier/dossier
- Import des packages `os/user` et `strconv`

**R√©sultat** :
```
-rw-r--r-- 1 test test  28K nov.  16 07:08 01.3mf
-rw-r--r-- 1 test test 181K nov.  16 07:08 02.3mf
-rw-r--r-- 1 test test 4.0K nov.  16 07:08 multi_size_pages.pdf
```
‚úÖ Ownership correct !

#### 3. Permissions /srv/anemone/backups (PAS UN PROBL√àME)
**Question** :
- L'utilisateur `franck` ne peut pas acc√©der √† `/srv/anemone/backups/`
- Permissions : `drwx------ root:root`

**R√©ponse** :
- C'est **normal et s√©curis√©** !
- Le service anemone tourne en tant que `root` : `User=root` (systemd)
- Seul le processus anemone doit avoir acc√®s aux donn√©es sensibles (backups, certs, db, smb)
- Les utilisateurs normaux (comme `franck`) n'ont pas besoin d'acc√®s direct
- ‚úÖ Bonne pratique de s√©curit√© respect√©e

### üìù Fichiers cr√©√©s/modifi√©s

**Nouveaux** :
- `web/templates/admin_restore_users.html` (~249 lignes) - Interface admin compl√®te

**Modifi√©s** :
- `internal/web/router.go` (~180 lignes ajout√©es)
  - `handleAdminRestoreUsers()` : Liste backups depuis tous les pairs
  - `handleAdminRestoreUsersRestore()` : Lance restauration en background
  - Routes : `/admin/restore-users`, `/admin/restore-users/restore`
  - Fix : Suppression filtre `peer.SyncEnabled`
- `web/templates/restore_warning.html` (~80 lignes modifi√©es)
  - Suppression option restauration automatique pour users
  - Ajout lien interface admin pour admins
- `restore_server.sh` (~5 lignes ajout√©es)
  - D√©sactivation automatique des pairs : `UPDATE peers SET sync_enabled = 0`
  - Messages d'avertissement
- `internal/bulkrestore/bulkrestore.go` (54 lignes modifi√©es, 19 supprim√©es)
  - **FIX CRITIQUE** : Utilisation cl√© map au lieu de file.Path vide
  - Ajout fonction `setOwnership()` pour ownership correct
  - Import `os/user` et `strconv`

**Total** : ~568 lignes ajout√©es/modifi√©es

### üîí S√©curit√©

**Garanties** :
- ‚úÖ Acc√®s restreint aux administrateurs (`RequireAdmin`)
- ‚úÖ Peers d√©sactiv√©s automatiquement lors de la restauration (pr√©vient data loss)
- ‚úÖ Isolation utilisateur : Chaque user ne peut restaurer que ses propres fichiers
- ‚úÖ Authentification P2P conserv√©e pour les requ√™tes aux pairs

**Workflow s√©curis√©** :
```
1. Admin lance restore_server.sh
2. Script d√©sactive tous les peers (sync_enabled = 0)
3. Admin se connecte √† l'interface web
4. Page "Ce serveur a √©t√© restaur√©" s'affiche
5. Admin clique "Acc√©der √† l'interface de restauration admin"
6. Admin voit la liste de tous les backups disponibles
7. Admin restaure les fichiers (un par un ou tous)
8. Admin r√©active manuellement les pairs quand c'est termin√©
```

### üß™ Tests effectu√©s et valid√©s

1. **Test restauration via API** : ‚úÖ
   - Commande curl : `POST /admin/restore-users/restore`
   - R√©sultat : 7 files, 280596 bytes, 0 errors
   - Temps : ~0.3 secondes

2. **Test ownership fichiers** : ‚úÖ
   - Tous les fichiers : `test:test` (correct)
   - Permissions : `0644` pour fichiers, `0755` pour dossiers
   - Accessibles via SMB

3. **Test permissions syst√®me** : ‚úÖ
   - Service anemone : tourne en `root` (systemd)
   - `/srv/anemone/backups/` : `drwx------ root:root` (s√©curis√©)
   - Seul anemone peut acc√©der aux donn√©es sensibles

4. **Test workflow disaster recovery complet** : ‚úÖ
   - FR1 ‚Üí backup sur FR2 ‚Üí arr√™t FR1 ‚Üí restore_server.sh sur FR3
   - Peers d√©sactiv√©s automatiquement (pr√©vient data loss)
   - Restauration admin depuis interface web
   - Fichiers accessibles via SMB

### üìù Commits

```
c9a7d10 - fix: Fix bulk restore to use manifest map keys and set proper file ownership (Session 18)
```

**D√©tails commit** :
- Correction utilisation cl√© map manifest au lieu de file.Path vide
- Ajout fonction setOwnership() pour ownership correct
- 54 insertions, 19 suppressions dans `internal/bulkrestore/bulkrestore.go`

**√âtat session 18** : üü¢ **COMPL√àTE - Restauration admin fonctionnelle √† 100%**

**Prochaine session** :
1. Tests complets de l'interface utilisateur (restauration depuis dashboard)
2. Audit de s√©curit√© complet (priorit√© 1 roadmap)
3. V√©rification d'int√©grit√© des backups (priorit√© 2 roadmap)

---

## üìù Prochaines √©tapes (Roadmap)

### üéØ Priorit√© 1 - Court terme

**Session 18 : Interface admin de restauration utilisateurs** üü¢ COMPL√àTE
- ‚úÖ Interface admin cr√©√©e (`/admin/restore-users`)
- ‚úÖ Fix bulk restore (utilisation cl√© map manifest)
- ‚úÖ Fix ownership fichiers restaur√©s (test:test)
- ‚úÖ Tests complets disaster recovery (7 files, 280596 bytes, 0 errors)

**Session 14 : Audit de s√©curit√© complet** üîí
- **Audit des permissions fichiers**
  - V√©rifier permissions `/srv/anemone/` (600/700)
  - V√©rifier ownership des fichiers sensibles
  - V√©rifier permissions base de donn√©es
  - V√©rifier permissions certificats TLS
- **Audit des cl√©s de chiffrement**
  - V√©rifier que la master key est uniquement en DB
  - V√©rifier le chiffrement des cl√©s utilisateurs
  - V√©rifier l'absence de cl√©s en clair sur le disque
  - Tester la rotation de cl√©s
- **Audit des endpoints API**
  - V√©rifier l'authentification sur tous les endpoints
  - Tester les tentatives d'acc√®s non autoris√©es
  - V√©rifier la protection CSRF
  - Tester les injections SQL
  - V√©rifier la validation des inputs
  - Tester path traversal sur les endpoints de fichiers

### ‚öôÔ∏è Priorit√© 2 - Am√©liorations

1. **Logs et audit trail** üìã
   - Table `audit_log` en base de donn√©es
   - Enregistrement actions importantes (user/peer CRUD, quotas, connexions)
   - Interface admin pour consulter les logs
   - Job de nettoyage automatique des anciens logs

2. **V√©rification d'int√©grit√© des backups** ‚úÖ
   - Commande `anemone-verify` pour v√©rification manuelle
   - V√©rification checksums depuis manifests
   - Option v√©rification p√©riodique en background
   - Alerte si corruption d√©tect√©e

3. **Rate limiting anti-bruteforce** üõ°Ô∏è
   - Protection sur `/login` et `/api/sync/*`
   - Bannissement temporaire apr√®s X tentatives √©chou√©es
   - Whitelist IP de confiance

4. **Statistiques d√©taill√©es de synchronisation** üìä
   - Graphiques d'utilisation (espace, fichiers, bande passante)
   - Historique des syncs sur 30 jours
   - Performance r√©seau par pair
   - Tableau de bord monitoring

### üöÄ Priorit√© 3 - √âvolutions futures

1. **Guide utilisateur complet** üìö
   - Guide d'installation pas-√†-pas avec captures d'√©cran
   - Guide d'utilisation pour chaque fonctionnalit√©
   - Exemples de configurations (topologies r√©seau)
   - FAQ et troubleshooting
   - Best practices s√©curit√© et performance
   - Disponible en FR et EN

2. **Syst√®me de notifications** üìß
   - **Module Home Assistant** via webhooks
   - **Webhooks g√©n√©riques** (Discord, Slack, custom)
   - **Email SMTP** (optionnel)
   - √âv√©nements notifiables : Sync r√©ussie/√©chou√©e, quota 80%+, nouveau pair, auth √©chou√©e

3. **Multi-peer redundancy**
   - Stockage sur plusieurs pairs simultan√©ment (2-of-3, 3-of-5)
   - Choix du niveau de redondance par partage
   - Reconstruction automatique en cas de perte d'un pair

### üìå Notes

- **Bandwidth throttling** : Non prioritaire car les fr√©quences diff√©renci√©es par pair permettent d√©j√† de planifier les syncs hors heures de pointe.

- **Politique de r√©tention automatique** : Remplac√©e par le syst√®me de fr√©quence de synchronisation par pair, permettant des snapshots √† diff√©rentes fr√©quences sans complexit√© suppl√©mentaire.

---

**√âtat global** : üü° INTERFACE ADMIN DE RESTAURATION EN COURS
**Prochaine √©tape** : Diagnostic et r√©solution probl√®me restauration + permissions
